import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';

import 'package:flutter/foundation.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart';
import 'audio_service.dart';
import 'aia_api_service.dart';

class OpenAIRealtimeService {
  RTCPeerConnection? _peerConnection;
  RTCDataChannel? _dataChannel;
  MediaStream? _localStream;
  MediaStream? _remoteStream;

  final VoidCallback? onListeningStarted;
  final VoidCallback? onConversationDone;
  final void Function(Uint8List)? onAudioResponse;
  final String? userName;

  bool _isConnected = false;
  bool get isConnected => _isConnected;
  bool _isProcessingConnection = false;

  // Vari√°vel para acumular a resposta da IA
  String _currentIAResponse = '';
  
  // Vari√°veis para salvar conversa
  String _currentUserMessage = '';
  List<Map<String, dynamic>> _conversationExchanges = [];
  DateTime? _conversationStartTime;
  DateTime? _currentExchangeStart;
  int _exchangeCounter = 0;

  // Estado de conversa√ß√£o com agentes especializados
  String? _activeAgentId;           // Qual agente est√° ativo (gmail_agent, calendar_agent)
  String? _activeSessionId;         // ID da sess√£o com o agente
  bool _isInAgentConversation = false;  // Se est√° em conversa com agente

  // Configura√ß√£o de ICE servers para WebRTC
  final Map<String, dynamic> _configuration = {
    'iceServers': [
      {'urls': 'stun:stun.l.google.com:19302'},
      {'urls': 'stun:stun1.l.google.com:19302'},
    ],
    'sdpSemantics': 'unified-plan'
  };

  OpenAIRealtimeService({
    this.onListeningStarted,
    this.onConversationDone,
    this.onAudioResponse,
    this.userName,
  });

  Future<bool> iniciarConexaoComOpenAI() async {
    if (_isProcessingConnection) {
      debugPrint('[OpenAI Realtime] J√° existe uma conex√£o em andamento');
      return false;
    }

    _isProcessingConnection = true;

    try {
      // Limpar qualquer conex√£o anterior
      await encerrarConversa();

      // Inicializar dados da conversa
      _conversationStartTime = DateTime.now();
      _conversationExchanges.clear();
      _exchangeCounter = 0;
      _currentUserMessage = '';
      _currentIAResponse = '';

      debugPrint('[OpenAI Realtime] Criando conex√£o WebRTC...');
      _peerConnection = await createPeerConnection(_configuration);

      // Configurar eventos de conex√£o
      _configurarEventosDeConexao();

      // Configurar canal de dados para eventos
      await _configurarCanalDeDados();

      // Capturar e adicionar √°udio local
      final success = await _configurarAudioLocal();
      if (!success) {
        debugPrint('[OpenAI Realtime] Falha ao configurar √°udio local');
        _isProcessingConnection = false;
        return false;
      }

      // Criar e enviar oferta SDP
      final success2 = await _criarEEnviarOferta();
      if (!success2) {
        debugPrint('[OpenAI Realtime] Falha ao criar e enviar oferta SDP');
        _isProcessingConnection = false;
        return false;
      }

      _isConnected = true;
      _isProcessingConnection = false;
      onListeningStarted?.call();
      return true;
    } catch (e) {
      debugPrint("[OpenAI Realtime] Erro ao iniciar conex√£o WebRTC: $e");
      _isProcessingConnection = false;
      return false;
    }
  }

  void _configurarEventosDeConexao() {
    _peerConnection!.onIceConnectionState = (RTCIceConnectionState state) {
      debugPrint('[OpenAI Realtime] ICE Connection State: ${state.toString()}');
      
      if (state == RTCIceConnectionState.RTCIceConnectionStateConnected) {
        debugPrint('[OpenAI Realtime] WebRTC conectado com sucesso');
      } else if (state == RTCIceConnectionState.RTCIceConnectionStateFailed ||
                state == RTCIceConnectionState.RTCIceConnectionStateDisconnected ||
                state == RTCIceConnectionState.RTCIceConnectionStateClosed) {
        debugPrint('[OpenAI Realtime] WebRTC desconectado: ${state.toString()}');
        _isConnected = false;
      }
    };

    _peerConnection!.onIceCandidate = (RTCIceCandidate candidate) {
      debugPrint('[OpenAI Realtime] ICE Candidate: ${candidate.candidate}');
    };

    _peerConnection!.onTrack = (RTCTrackEvent event) {
      debugPrint('[OpenAI Realtime] Faixa remota recebida: ${event.track.kind}');
      
      if (event.track.kind == 'audio') {
        _remoteStream = event.streams[0];
        debugPrint('[OpenAI Realtime] √Åudio remoto recebido e configurado para reprodu√ß√£o');
      }
    };
  }

  Future<void> _configurarCanalDeDados() async {
    final dcInit = RTCDataChannelInit();
    dcInit.ordered = true;
    
    _dataChannel = await _peerConnection!.createDataChannel("oai-events", dcInit);
    
    _dataChannel!.onMessage = (RTCDataChannelMessage message) {
      _processarMensagem(message.text);
    };
    
    _dataChannel!.onDataChannelState = (RTCDataChannelState state) {
      debugPrint('[OpenAI Realtime] Estado do canal de dados: ${state.toString()}');
      
      if (state == RTCDataChannelState.RTCDataChannelOpen) {
        debugPrint('[OpenAI Realtime] Canal de dados aberto, enviando configura√ß√£o');
        _enviarConfiguracao();
      }
    };
  }

  Future<bool> _configurarAudioLocal() async {
    try {
      final success = await AudioService.iniciarCapturaDeAudio((_) {});
      if (!success) return false;

      _localStream = AudioService.getMediaStream();
      if (_localStream == null) {
        debugPrint('[OpenAI Realtime] Falha ao obter stream de √°udio local');
        return false;
      }

      for (var track in _localStream!.getAudioTracks()) {
        debugPrint('[OpenAI Realtime] Adicionando faixa de √°udio: ${track.id}');
        await _peerConnection!.addTrack(track, _localStream!);
      }
      
      // Configurar volume m√°ximo para o sistema
      AudioService.maximizeSystemVolume();
      debugPrint('[OpenAI Realtime] üîä Volume do sistema configurado para m√°ximo');
      
      return true;
    } catch (e) {
      debugPrint('[OpenAI Realtime] Erro ao configurar √°udio local: $e');
      return false;
    }
  }

  Future<bool> _criarEEnviarOferta() async {
    try {
      // Criar oferta SDP
      final offerOptions = <String, dynamic>{
        'offerToReceiveAudio': true,
        'offerToReceiveVideo': false,
        'voiceActivityDetection': true,
      };
      
      final offer = await _peerConnection!.createOffer(offerOptions);
      await _peerConnection!.setLocalDescription(offer);
      
      debugPrint('[OpenAI Realtime] Oferta SDP criada: ${offer.sdp}');

      // Enviar oferta para a OpenAI usando HttpClient para controle preciso dos cabe√ßalhos
      final client = HttpClient();
      final uri = Uri.parse("https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17");
      final request = await client.postUrl(uri);
      
      // Configurar cabe√ßalhos exatamente como a API espera
      request.headers.set('Authorization', 'Bearer ${dotenv.env['OPENAI_API_KEY']}');
      request.headers.set('Content-Type', 'application/sdp');
      
      // Enviar o corpo da requisi√ß√£o
      request.write(offer.sdp);
      
      // Obter resposta
      final response = await request.close();
      final responseBody = await response.transform(utf8.decoder).join();
      
      // Verificar se a resposta come√ßa com "v=0", que √© o in√≠cio de um SDP v√°lido
      if (responseBody.trim().startsWith('v=0')) {
        debugPrint('[OpenAI Realtime] Resposta SDP recebida com sucesso');
      } else {
        // Verificar se a resposta √© um JSON de erro
        try {
          if (response.statusCode != 200) {
            debugPrint('[OpenAI Realtime] Erro HTTP: ${response.statusCode}');
            try {
              final errorJson = jsonDecode(responseBody);
              if (errorJson.containsKey('error')) {
                if (errorJson['error'] is Map) {
                  debugPrint('[OpenAI Realtime] Erro da API OpenAI: ${errorJson['error']['message']}');
                } else {
                  debugPrint('[OpenAI Realtime] Erro da API OpenAI: ${errorJson['error']}');
                }
              } else {
                debugPrint('[OpenAI Realtime] Erro ao obter SDP da OpenAI: $responseBody');
              }
            } catch (e) {
              // Se n√£o for JSON, apenas exibir a resposta como est√°
              debugPrint('[OpenAI Realtime] Erro ao obter SDP da OpenAI: $responseBody');
            }
          } else {
            debugPrint('[OpenAI Realtime] Resposta inesperada da API: $responseBody');
          }
        } catch (e) {
          debugPrint('[OpenAI Realtime] Erro ao processar resposta: $e');
        }
        
        // Aguardar um pouco antes de tentar novamente
        await Future.delayed(Duration(seconds: 2));
        
        // Tentar novamente uma vez
        debugPrint('[OpenAI Realtime] Tentando reconectar ap√≥s erro...');
        return await _tentarReconectar();
      }
      
      try {
        // Configurar resposta como descri√ß√£o remota
        await _peerConnection!.setRemoteDescription(
          RTCSessionDescription(responseBody, 'answer'),
        );
        debugPrint('[OpenAI Realtime] Descri√ß√£o remota configurada com sucesso');
        return true;
      } catch (e) {
        debugPrint('[OpenAI Realtime] Erro ao configurar descri√ß√£o remota: $e');
        return false;
      }
    } catch (e) {
      debugPrint('[OpenAI Realtime] Erro ao criar e enviar oferta: $e');
      return false;
    }
  }

  void _processarMensagem(String rawData) {
    try {
      debugPrint('[OpenAI Realtime] Mensagem recebida: $rawData');
      final data = jsonDecode(rawData);
      final type = data['type'];

      switch (type) {
        case 'session.created':
          debugPrint('[OpenAI Realtime] Sess√£o criada, ID: ${data['session']['id']}');
          _enviarConfiguracao();
          break;
          
        case 'session.updated':
          debugPrint('[OpenAI Realtime] Sess√£o atualizada, pronta para ouvir');
          onListeningStarted?.call();
          break;
          
        case 'rate_limits.updated':
          debugPrint('[OpenAI Realtime] Limites de taxa atualizados');
          break;
          
        case 'input_audio_buffer.speech_started':
          debugPrint('[OpenAI Realtime] Usu√°rio come√ßou a falar');
          break;
          
        case 'input_audio_buffer.speech_stopped':
          debugPrint('[OpenAI Realtime] Usu√°rio parou de falar');
          break;
          
        case 'output_audio_buffer.started':
          debugPrint('[OpenAI Realtime] IA come√ßou a falar');
          break;
          
        case 'output_audio_buffer.stopped':
          debugPrint('[OpenAI Realtime] IA parou de falar');
          break;
          
        case 'response.audio.delta':
          final bytes = base64Decode(data['delta']);
          debugPrint('[OpenAI Realtime] √Åudio delta recebido: ${bytes.length} bytes');
          onAudioResponse?.call(Uint8List.fromList(bytes));
          break;
          
        case 'response.audio.done':
          debugPrint('[OpenAI Realtime] √Åudio da resposta conclu√≠do');
          break;
          
        case 'response.done':
          debugPrint('[OpenAI Realtime] Resposta conclu√≠da');
          onConversationDone?.call();
          break;
          
        case 'error':
          // Verificar se o erro tem uma mensagem
          if (data.containsKey('error') && data['error'] is Map && data['error'].containsKey('message')) {
            debugPrint('[OpenAI Realtime] Erro recebido: ${data['error']['message']}');
          } else if (data.containsKey('message')) {
            debugPrint('[OpenAI Realtime] Erro recebido: ${data['message']}');
          } else {
            debugPrint('[OpenAI Realtime] Erro recebido sem mensagem detalhada');
          }
          break;
          
        // Capturar transcri√ß√£o do usu√°rio (delta - em tempo real)
        case 'conversation.item.input_audio_transcription.delta':
          final delta = data['delta'] as String?;
          if (delta != null) {
            debugPrint('[OpenAI Realtime] Transcri√ß√£o delta: "$delta"');
          }
          break;
          
        // Capturar transcri√ß√£o do usu√°rio (completa)
        case 'conversation.item.input_audio_transcription.completed':
          final transcript = data['transcript'] as String?;
          if (transcript != null && transcript.trim().isNotEmpty) {
            _currentUserMessage = transcript.trim();
            _currentExchangeStart = DateTime.now();
            debugPrint('[OpenAI Realtime] Fala do usu√°rio: "$transcript"');
            
            // Verificar se est√° em conversa com agente
            if (_isInAgentConversation) {
              // Usu√°rio est√° respondendo ao agente
              debugPrint('[OpenAI Realtime] üîÑ Continuando conversa com agente: $_activeAgentId');
              _continuarConversaComAgente(transcript);
            }
          }
          break;
          
        // Capturar chamadas de fun√ß√£o
        case 'response.function_call_arguments.delta':
          debugPrint('[OpenAI Realtime] Function call delta: ${data['delta']}');
          break;
          
        case 'response.function_call_arguments.done':
          final functionName = data['name'] as String?;
          final arguments = data['arguments'] as String?;
          debugPrint('[OpenAI Realtime] Function call: $functionName com argumentos: $arguments');
          
          if (functionName == 'execute_task' && arguments != null) {
            try {
              final args = jsonDecode(arguments);
              final message = args['message'] as String?;
              if (message != null) {
                _executarTarefaViaAIA(message);
              }
            } catch (e) {
              debugPrint('[OpenAI Realtime] Erro ao processar argumentos da fun√ß√£o: $e');
            }
          }
          break;

        // Capturar resposta da IA em texto (delta)
        case 'response.audio_transcript.delta':
          final delta = data['delta'] as String?;
          if (delta != null) {
            _currentIAResponse += delta;
          }
          break;
          
        // Capturar resposta da IA em texto (completa)
        case 'response.audio_transcript.done':
          if (_currentIAResponse.trim().isNotEmpty && _currentUserMessage.isNotEmpty) {
            _exchangeCounter++;
            
            final exchange = {
              "exchange_id": _exchangeCounter,
              "timestamp": _currentExchangeStart?.toIso8601String(),
              "user_message": _currentUserMessage,
              "ai_response": _currentIAResponse,
              "duration_ms": DateTime.now().difference(_currentExchangeStart ?? DateTime.now()).inMilliseconds
            };
            
            _conversationExchanges.add(exchange);
            debugPrint('[OpenAI Realtime] Resposta da IA: "$_currentIAResponse"');
            debugPrint('[OpenAI Realtime] Troca ${_exchangeCounter} adicionada √† conversa');
            
            // Limpar para pr√≥xima troca
            _currentIAResponse = '';
            _currentUserMessage = '';
          }
          break;
          
        default:
          debugPrint("[OpenAI Realtime] Evento desconhecido: $type");
      }
    } catch (e) {
      debugPrint("[OpenAI Realtime] Erro ao processar evento: $e");
    }
  }

  void _enviarConfiguracao() async {
    if (_dataChannel?.state == RTCDataChannelState.RTCDataChannelOpen) {
      String instructions = '''
# Prompt - AIA (Assistente Principal Multi-Agente) - AIAPROJECT

## IDENTIDADE E CONTEXTO
Voc√™ √© a **AIA**, uma assistente de IA conversacional que atua como coordenadora principal em um sistema multi-agente do AIAPROJECT. Voc√™ se comunica exclusivamente por √°udio em portugu√™s brasileiro, sendo a interface principal entre o usu√°rio e 7 agentes especializados.

## AGENTES ESPECIALIZADOS DISPON√çVEIS

### üìß **Gmail Agent** - Gerenciamento de Emails
- Enviar emails, buscar mensagens, gerenciar caixa de entrada
- **CONFIGURA√á√ÉO ESPECIAL**: TODOS os emails v√£o para `lucas.arais@inventu.ai`

### üìÖ **Calendar Agent** - Gerenciamento de Agenda
- Criar eventos, agendar reuni√µes, consultar disponibilidade
- Suporte a linguagem natural para datas

### ‚úàÔ∏è **Travel Agent** - Planejamento de Viagens
- Busca de voos, reservas, informa√ß√µes de aeroportos
- Integra√ß√£o com Amadeus API para dados reais
- Previs√£o de atrasos com Machine Learning

### üöó **Vehicle Agent** - Informa√ß√µes Veiculares
- Consulta RENAVAM por placa, verifica√ß√£o de d√©bitos
- Pre√ßos FIPE, informa√ß√µes de ve√≠culos brasileiros
- Suporte placas antigas (ABC1234) e Mercosul (ABC1D23)
- **EXEMPLO MOCKADO**: Para demonstra√ß√£o, use a placa DQQ1778

### ‚è∞ **Reminder Agent** - Gerenciamento de Lembretes ‚ú® (CORRIGIDO)
- Criar lembretes para datas importantes
- Configura√ß√£o flex√≠vel de tempo (dias, minutos, segundos)
- Cancelamento e listagem de lembretes ativos
- Sistema de notifica√ß√µes aprimorado

### üì± **WhatsApp Agent** - Automa√ß√£o WhatsApp ‚ú® (MELHORADO)
- Envio de mensagens, m√≠dia e documentos
- Cria√ß√£o e gerenciamento completo de grupos
- Autentica√ß√£o por QR code ou pareamento telef√¥nico
- Rea√ß√µes, status de presen√ßa e localiza√ß√£o
- Verifica√ß√£o de n√∫meros e gest√£o de contatos
- Opera√ß√µes em lote controladas e boas pr√°ticas

### üçï **Food Delivery Agent** - iFood e Delivery üÜï (NOVO!)
- Busca de restaurantes por tipo de comida e localiza√ß√£o
- Integra√ß√£o com iFood (principal plataforma brasileira)
- Gera√ß√£o de deeplinks para apps m√≥veis
- Informa√ß√µes de entrega, pre√ßos e avalia√ß√µes
- Suporte a coordenadas GPS para busca precisa
- Foco no mercado brasileiro de delivery

## PRINC√çPIOS FUNDAMENTAIS
- **Conversa Natural**: Mantenha sempre um tom conversacional, emp√°tico e prestativo
- **Efici√™ncia Inteligente**: Colete todas as informa√ß√µes necess√°rias ANTES de executar qualquer a√ß√£o
- **Fluidez**: Fa√ßa perguntas naturais e org√¢nicas, evitando interrogat√≥rios rob√≥ticos
- **Completude**: NUNCA execute uma a√ß√£o sem ter 100% das informa√ß√µes obrigat√≥rias

## INFORMA√á√ïES OBRIGAT√ìRIAS POR CATEGORIA

### üìß **EMAILS**
**Obrigat√≥rio coletar:**
- Assunto do email
- Conte√∫do completo da mensagem
**SEMPRE informe**: "Vou enviar para o Lucas (lucas.arais@inventu.ai)"

### üìÖ **REUNI√ïES**
**Obrigat√≥rio coletar:**
- Participantes da reuni√£o
- Data e hor√°rio
- Dura√ß√£o estimada
- Assunto/pauta da reuni√£o

### ‚úàÔ∏è **VIAGENS**
**Obrigat√≥rio coletar:**
- Local de origem
- Destino
- Data e hor√°rio desejados
- Tipo de transporte preferido

### üöó **VE√çCULOS**
**Para consulta RENAVAM:**
- Placa do ve√≠culo (formato ABC1234 ou ABC1D23)
**Para pre√ßos FIPE:**
- Marca, modelo e ano do ve√≠culo

### ‚è∞ **LEMBRETES**
**Obrigat√≥rio coletar:**
- Evento/tarefa para lembrar
- Data e hor√°rio do lembrete
- Anteced√™ncia desejada (opcional)

### üì± **WHATSAPP**
**Para envio de mensagens:**
- N√∫mero de telefone (formato +55XXXXXXXXXXX)
- Conte√∫do da mensagem
**Para grupos:**
- Nome do grupo e participantes

### üçï **FOOD DELIVERY**
**Para busca de restaurantes:**
- Tipo de comida desejada (pizza, hamb√∫rguer, sushi, etc.)
- Localiza√ß√£o (coordenadas GPS ou endere√ßo)
**Para pedidos:**
- Restaurante escolhido e itens do card√°pio

## FERRAMENTAS DISPON√çVEIS

Voc√™ tem acesso a uma ferramenta chamada `execute_task` que permite executar a√ß√µes espec√≠ficas atrav√©s de agentes especializados. Use esta ferramenta SOMENTE quando tiver TODAS as informa√ß√µes necess√°rias para completar uma tarefa.

### Quando usar execute_task:
- **Emails**: Quando tiver assunto E conte√∫do completos
- **Reuni√µes**: Quando tiver participantes, data, hor√°rio E assunto
- **Viagens**: Quando tiver origem, destino, data E tipo de transporte
- **Ve√≠culos**: Quando tiver placa OU marca/modelo/ano
- **Lembretes**: Quando tiver evento E data/hor√°rio
- **WhatsApp**: Quando tiver n√∫mero E mensagem OU dados do grupo
- **Food Delivery**: Quando tiver tipo de comida E localiza√ß√£o

## REGRAS CR√çTICAS

1. **NUNCA** use execute_task sem ter TODAS as informa√ß√µes obrigat√≥rias
2. **SEMPRE** colete informa√ß√µes primeiro, execute depois
3. **SEMPRE** informe que emails v√£o para lucas.arais@inventu.ai
4. **MANTENHA** a conversa natural e fluida, evite soar rob√≥tico
5. **RESPONDA** sempre pensando que ser√° convertido em √°udio
6. **SEJA** paciente e educado, mesmo se o usu√°rio n√£o fornecer informa√ß√µes claras
7. **IDENTIFIQUE** automaticamente qual agente usar baseado no contexto da solicita√ß√£o

## EXEMPLOS DE USO

**Ve√≠culos**: "Consultar placa ABC1234" ‚Üí Vehicle Agent
**Lembretes**: "Me lembre de pagar a conta amanh√£ √†s 9h" ‚Üí Reminder Agent  
**WhatsApp**: "Enviar mensagem no WhatsApp para +5511999999999" ‚Üí WhatsApp Agent
**Viagens**: "Quero um voo para S√£o Paulo amanh√£" ‚Üí Travel Agent
**Emails**: "Enviar email sobre reuni√£o" ‚Üí Gmail Agent
**Agenda**: "Agendar reuni√£o para quinta-feira" ‚Üí Calendar Agent
**Food Delivery**: "Quero pedir pizza aqui perto" ‚Üí Food Delivery Agent

Lembre-se: voc√™ √© a coordenadora inteligente de 7 agentes especializados que garante que todas as a√ß√µes sejam executadas corretamente, coletando informa√ß√µes de forma natural e conversacional.
''';

      // Personalizar com nome do usu√°rio se dispon√≠vel
      if (userName != null && userName!.isNotEmpty) {
        instructions = instructions.replaceAll('Usu√°rio', userName!);
      }

      debugPrint('[OpenAI Realtime] üîç PROMPT SENDO USADO:');
      debugPrint('[OpenAI Realtime] üìù Tamanho: ${instructions.length} chars');
      debugPrint('[OpenAI Realtime] üéØ Cont√©m Vehicle Agent: ${instructions.contains('Vehicle Agent')}');
      debugPrint('[OpenAI Realtime] üéØ Cont√©m Reminder Agent: ${instructions.contains('Reminder Agent')}');
      debugPrint('[OpenAI Realtime] üéØ Cont√©m WhatsApp Agent: ${instructions.contains('WhatsApp Agent')}');
      debugPrint('[OpenAI Realtime] üéØ Cont√©m Food Delivery Agent: ${instructions.contains('Food Delivery Agent')}');

      final settings = {
        "type": "session.update",
        "session": {
          "modalities": ["audio", "text"],
          "voice": "sage",
          "output_audio_format": "pcm16",
          "input_audio_format": "pcm16",
          "input_audio_transcription": {
            "model": "whisper-1",
          },
          "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "silence_duration_ms": 500,
            "prefix_padding_ms": 200,
            "create_response": true
          },
          "temperature": 0.8,
          "max_response_output_tokens": "inf",
          "instructions": instructions,
          "tools": [
            {
              "type": "function",
              "name": "execute_task",
              "description": "Executa uma tarefa espec√≠fica atrav√©s de agentes especializados. Use SOMENTE quando tiver TODAS as informa√ß√µes necess√°rias.",
              "parameters": {
                "type": "object",
                "properties": {
                  "message": {
                    "type": "string",
                    "description": "Mensagem completa com todas as informa√ß√µes necess√°rias para executar a tarefa (ex: 'Enviar email com assunto X e conte√∫do Y para lucas.arais@inventu.ai')"
                  }
                },
                "required": ["message"]
              }
            }
          ]
        }
      };
      
      debugPrint('[OpenAI Realtime] üáßüá∑ Configura√ß√£o com idioma portugu√™s for√ßado');

      final jsonString = jsonEncode(settings);
      debugPrint('[OpenAI Realtime] üì§ Enviando configura√ß√£o para OpenAI...');
      debugPrint('[OpenAI Realtime] üìä Tamanho da configura√ß√£o: ${jsonString.length} chars');
      _dataChannel!.send(RTCDataChannelMessage(jsonString));
    } else {
      debugPrint("[OpenAI Realtime] ‚ùå Canal de dados n√£o est√° pronto. Estado: ${_dataChannel?.state}");
    }
  }

  /// Inicia conversa cont√≠nua com agente especializado
  Future<void> _iniciarConversaComAgente(String message, String intent) async {
    try {
      debugPrint('[OpenAI Realtime] üöÄ Iniciando conversa com agente: $message');
      
      final result = await AIAApiService.executeTask(message, userId: userName);
      
      if (result != null && result['success'] == true) {
        final response = result['response'] as String? ?? result['message'] as String? ?? 'Tarefa iniciada';
        final agentUsed = result['agent_used'] as String? ?? 'unknown';
        final sessionId = result['session_id'] as String?;
        
        // Configurar estado da conversa apenas se h√° session_id
        if (sessionId != null) {
          _activeAgentId = agentUsed;
          _activeSessionId = sessionId;
          _isInAgentConversation = true;
          
          debugPrint('[OpenAI Realtime] üîÑ Conversa iniciada com agente: $agentUsed');
          debugPrint('[OpenAI Realtime] üìä Session ID: $sessionId');
        } else {
          debugPrint('[OpenAI Realtime] ‚úÖ Resposta direta do agente: $agentUsed');
          _finalizarConversaComAgente();
        }
        
        // Repassa resposta do agente para o usu√°rio
        _enviarMensagemDoSistema(response);
        
      } else {
        debugPrint('[OpenAI Realtime] ‚ùå Falha ao iniciar conversa com agente');
        _enviarMensagemDoSistema('N√£o foi poss√≠vel executar a tarefa solicitada no momento.');
      }
    } catch (e) {
      debugPrint('[OpenAI Realtime] ‚ùå Erro ao iniciar conversa com agente: $e');
      _enviarMensagemDoSistema('Ocorreu um erro ao tentar executar a tarefa.');
    }
  }

  /// Continua conversa com agente especializado
  Future<void> _continuarConversaComAgente(String userResponse) async {
    try {
      debugPrint('[OpenAI Realtime] üîÑ Continuando conversa com $_activeAgentId: $userResponse');
      
      final result = await AIAApiService.executeTask(
        userResponse, 
        userId: userName,
        sessionId: _activeSessionId,
      );
      
      if (result != null && result['success'] == true) {
        final response = result['message'] as String? ?? result['response'] as String? ?? 'Resposta recebida';
        final isCompleted = result['completed'] as bool? ?? false;
        
        if (isCompleted) {
          // Tarefa finalizada
          debugPrint('[OpenAI Realtime] ‚úÖ Tarefa conclu√≠da com $_activeAgentId');
          _finalizarConversaComAgente();
          _enviarMensagemDoSistema('Tarefa conclu√≠da: $response');
        } else {
          // Agente precisa de mais informa√ß√µes
          debugPrint('[OpenAI Realtime] üîÑ Agente $_activeAgentId precisa de mais informa√ß√µes');
          _enviarMensagemDoSistema(response);
        }
        
      } else {
        debugPrint('[OpenAI Realtime] ‚ùå Erro na continua√ß√£o da conversa');
        _finalizarConversaComAgente();
        _enviarMensagemDoSistema('Ocorreu um erro durante a execu√ß√£o da tarefa.');
      }
    } catch (e) {
      debugPrint('[OpenAI Realtime] ‚ùå Erro ao continuar conversa: $e');
      _finalizarConversaComAgente();
      _enviarMensagemDoSistema('Ocorreu um erro durante a conversa com o agente.');
    }
  }

  /// Finaliza conversa com agente especializado
  void _finalizarConversaComAgente() {
    debugPrint('[OpenAI Realtime] üèÅ Finalizando conversa com agente: $_activeAgentId');
    _activeAgentId = null;
    _activeSessionId = null;
    _isInAgentConversation = false;
  }

  /// Executa tarefa via API AIA (m√©todo legado para compatibilidade)
  Future<void> _executarTarefaViaAIA(String message, [String? intent]) async {
    // Redirecionar para o novo m√©todo
    _iniciarConversaComAgente(message, intent ?? 'general');
  }
  
  /// Envia mensagem do sistema para o OpenAI
  void _enviarMensagemDoSistema(String mensagem) {
    if (_dataChannel?.state == RTCDataChannelState.RTCDataChannelOpen) {
      final systemMessage = {
        "type": "conversation.item.create",
        "item": {
          "type": "message",
          "role": "system",
          "content": [
            {
              "type": "input_text",
              "text": mensagem
            }
          ]
        }
      };
      
      final jsonString = jsonEncode(systemMessage);
      debugPrint('[OpenAI Realtime] üì§ Enviando mensagem do sistema: $mensagem');
      _dataChannel!.send(RTCDataChannelMessage(jsonString));
      
      // Solicitar resposta
      final responseRequest = {
        "type": "response.create"
      };
      
      _dataChannel!.send(RTCDataChannelMessage(jsonEncode(responseRequest)));
    }
  }

  Future<bool> _tentarReconectar() async {
    try {
      debugPrint('[OpenAI Realtime] Tentando reconectar...');
      
      // Criar nova oferta SDP
      final offerOptions = <String, dynamic>{
        'offerToReceiveAudio': true,
        'offerToReceiveVideo': false,
        'voiceActivityDetection': true,
      };
      
      final offer = await _peerConnection!.createOffer(offerOptions);
      await _peerConnection!.setLocalDescription(offer);
      
      debugPrint('[OpenAI Realtime] Nova oferta SDP criada para reconex√£o');

      // Enviar oferta para a OpenAI
      final client = HttpClient();
      final uri = Uri.parse("https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17");
      final request = await client.postUrl(uri);
      
      request.headers.set('Authorization', 'Bearer ${dotenv.env['OPENAI_API_KEY']}');
      request.headers.set('Content-Type', 'application/sdp');
      
      request.write(offer.sdp);
      
      final response = await request.close();
      final responseBody = await response.transform(utf8.decoder).join();
      
      if (responseBody.trim().startsWith('v=0')) {
        debugPrint('[OpenAI Realtime] Reconex√£o bem-sucedida');
        
        await _peerConnection!.setRemoteDescription(
          RTCSessionDescription(responseBody, 'answer'),
        );
        
        return true;
      } else {
        debugPrint('[OpenAI Realtime] Falha na reconex√£o: resposta inv√°lida');
        return false;
      }
    } catch (e) {
      debugPrint('[OpenAI Realtime] Erro durante a reconex√£o: $e');
      return false;
    }
  }

  /// Muta o √°udio do OpenAI Realtime
  void muteAudio() {
    try {
      if (_localStream != null) {
        for (var track in _localStream!.getAudioTracks()) {
          track.enabled = false;
        }
        debugPrint('[OpenAI Realtime] üîá √Åudio mutado');
      }
      
      if (_remoteStream != null) {
        for (var track in _remoteStream!.getAudioTracks()) {
          track.enabled = false;
        }
      }
    } catch (e) {
      debugPrint('[OpenAI Realtime] Erro ao mutar √°udio: $e');
    }
  }

  /// Desmuta o √°udio do OpenAI Realtime
  void unmuteAudio() {
    try {
      if (_localStream != null) {
        for (var track in _localStream!.getAudioTracks()) {
          track.enabled = true;
        }
        debugPrint('[OpenAI Realtime] üîä √Åudio desmutado');
      }
      
      if (_remoteStream != null) {
        for (var track in _remoteStream!.getAudioTracks()) {
          track.enabled = true;
        }
      }
    } catch (e) {
      debugPrint('[OpenAI Realtime] Erro ao desmutar √°udio: $e');
    }
  }

  Future<void> encerrarConversa() async {
    debugPrint('[OpenAI Realtime] Encerrando conversa...');
    
    try {
      await AudioService.pararCapturaDeAudio();
      
      if (_dataChannel != null) {
        await _dataChannel!.close();
        _dataChannel = null;
      }
      
      if (_localStream != null) {
        _localStream!.getTracks().forEach((track) => track.stop());
        await _localStream!.dispose();
        _localStream = null;
      }
      
      if (_remoteStream != null) {
        _remoteStream!.getTracks().forEach((track) => track.stop());
        await _remoteStream!.dispose();
        _remoteStream = null;
      }
      
      if (_peerConnection != null) {
        await _peerConnection!.close();
        _peerConnection = null;
      }
      
      _isConnected = false;
      debugPrint('[OpenAI Realtime] Conversa encerrada com sucesso');
    } catch (e) {
      debugPrint('[OpenAI Realtime] Erro ao encerrar conversa: $e');
    }
  }
}

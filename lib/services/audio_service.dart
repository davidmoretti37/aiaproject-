import 'dart:async';
import 'dart:io' show Platform;
import 'package:flutter/foundation.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart';
import 'package:permission_handler/permission_handler.dart';

class AudioService {
  static MediaStream? _localStream;
  static MediaStreamTrack? _audioTrack;
  static bool _isCapturing = false;
  static bool _isInitialized = false;

  static bool get isCapturing => _isCapturing;

  /// Solicita permiss√£o de microfone usando WebRTC diretamente
  /// Este m√©todo FOR√áA o iOS a mostrar o dialog de permiss√£o
  static Future<bool> solicitarPermissaoMicrofoneViaWebRTC() async {
    try {
      debugPrint('[AudioService] üé§ FOR√áANDO solicita√ß√£o de permiss√£o via WebRTC...');
      debugPrint('[AudioService] üì± Plataforma: ${Platform.isIOS ? 'iOS' : Platform.isAndroid ? 'Android' : 'Outra'}');
      
      // Tentar acessar o microfone diretamente via WebRTC
      // Isso FOR√áA o iOS a mostrar o dialog de permiss√£o
      final Map<String, dynamic> mediaConstraints = {
        'audio': true,
        'video': false,
      };
      
      debugPrint('[AudioService] üîÑ Chamando getUserMedia para for√ßar dialog...');
      
      MediaStream? testStream;
      try {
        testStream = await navigator.mediaDevices.getUserMedia(mediaConstraints);
        
        if (testStream != null) {
          debugPrint('[AudioService] ‚úÖ Permiss√£o concedida via WebRTC!');
          
          // Limpar o stream de teste
          testStream.getTracks().forEach((track) => track.stop());
          await testStream.dispose();
          
          return true;
        } else {
          debugPrint('[AudioService] ‚ùå getUserMedia retornou null');
          return false;
        }
      } catch (webRtcError) {
        debugPrint('[AudioService] üö® Erro no WebRTC: $webRtcError');
        
        // Analisar o tipo de erro para determinar a causa
        final errorString = webRtcError.toString().toLowerCase();
        
        if (errorString.contains('notallowederror') || 
            errorString.contains('permission') ||
            errorString.contains('denied')) {
          debugPrint('[AudioService] ‚ùå Usu√°rio negou a permiss√£o via WebRTC');
          return false;
        } else if (errorString.contains('notfounderror') ||
                   errorString.contains('devicenotfound')) {
          debugPrint('[AudioService] üîç Dispositivo de √°udio n√£o encontrado');
          return false;
        } else {
          debugPrint('[AudioService] ‚ö†Ô∏è Erro desconhecido no WebRTC: $webRtcError');
          return false;
        }
      }
    } catch (e, stackTrace) {
      debugPrint('[AudioService] ‚ùå Exce√ß√£o geral ao solicitar permiss√£o via WebRTC: $e');
      debugPrint('[AudioService] üìö Stack trace: $stackTrace');
      return false;
    }
  }

  /// M√©todo h√≠brido que tenta permission_handler primeiro, depois WebRTC
  static Future<bool> solicitarPermissaoMicrofone() async {
    try {
      debugPrint('[AudioService] üé§ Iniciando solicita√ß√£o h√≠brida de permiss√£o...');
      
      // Primeiro, verificar status atual via permission_handler
      final statusAtual = await Permission.microphone.status;
      debugPrint('[AudioService] üìä Status atual via permission_handler: $statusAtual');
      
      if (statusAtual.isGranted) {
        debugPrint('[AudioService] ‚úÖ Permiss√£o j√° concedida');
        return true;
      }
      
      // Se permission_handler diz que est√° permanentemente negada, 
      // ainda assim tentar WebRTC (pode estar errado)
      if (statusAtual.isPermanentlyDenied) {
        debugPrint('[AudioService] ‚ö†Ô∏è permission_handler diz permanentemente negada, mas tentando WebRTC...');
      }
      
      // SEMPRE tentar WebRTC para for√ßar o dialog do iOS
      debugPrint('[AudioService] üîÑ Tentando WebRTC para for√ßar dialog...');
      final webRtcResult = await solicitarPermissaoMicrofoneViaWebRTC();
      
      if (webRtcResult) {
        debugPrint('[AudioService] ‚úÖ Permiss√£o concedida via WebRTC!');
        return true;
      } else {
        debugPrint('[AudioService] ‚ùå Permiss√£o negada via WebRTC');
        
        // Verificar status final
        final statusFinal = await Permission.microphone.status;
        debugPrint('[AudioService] üìä Status final: $statusFinal');
        
        return false;
      }
    } catch (e, stackTrace) {
      debugPrint('[AudioService] ‚ùå Erro na solicita√ß√£o h√≠brida: $e');
      debugPrint('[AudioService] üìö Stack trace: $stackTrace');
      return false;
    }
  }

  static Future<bool> iniciarCapturaDeAudio(void Function(List<int>) onAudioData) async {
    try {
      if (_isCapturing) {
        debugPrint('[AudioService] J√° est√° capturando √°udio');
        return true;
      }

      // Parar qualquer captura anterior
      await pararCapturaDeAudio();

      debugPrint('[AudioService] üé§ Iniciando captura de √°udio - verificando permiss√µes primeiro...');
      
      // AGORA solicitar permiss√£o apenas quando realmente precisar
      final permissaoOk = await solicitarPermissaoMicrofone();
      if (!permissaoOk) {
        debugPrint('[AudioService] ‚ùå Permiss√£o de microfone negada - n√£o √© poss√≠vel capturar √°udio');
        return false;
      }
      
      debugPrint('[AudioService] ‚úÖ Permiss√£o concedida - iniciando WebRTC...');
      
      // Usar constraints otimizadas para melhor qualidade e volume
      final mediaConstraints = getOptimizedAudioConstraints();

      _localStream = await navigator.mediaDevices.getUserMedia(mediaConstraints);
      
      if (_localStream == null) {
        debugPrint('[AudioService] Falha ao obter stream de √°udio');
        return false;
      }
      
      final audioTracks = _localStream!.getAudioTracks();
      if (audioTracks.isEmpty) {
        debugPrint('[AudioService] Nenhuma faixa de √°udio dispon√≠vel');
        return false;
      }
      
      _audioTrack = audioTracks.first;
      _audioTrack!.enabled = true;
      
      debugPrint('[AudioService] Captura de √°udio iniciada com sucesso');
      _isCapturing = true;
      _isInitialized = true;
      return true;
    } catch (e) {
      debugPrint('[AudioService] Erro ao iniciar captura de √°udio via WebRTC: $e');
      
      // Se o erro for relacionado a permiss√£o, tentar diagnosticar
      if (e.toString().contains('Permission') || e.toString().contains('NotAllowed')) {
        debugPrint('[AudioService] üö® Erro parece ser relacionado a permiss√£o: $e');
        final status = await verificarStatusPermissao();
        debugPrint('[AudioService] üìä Status atual da permiss√£o ap√≥s erro: $status');
      }
      
      return false;
    }
  }

  static Future<void> pararCapturaDeAudio() async {
    if (!_isCapturing && _localStream == null) {
      return;
    }

    debugPrint('[AudioService] Parando captura de √°udio');
    _isCapturing = false;

    try {
      if (_audioTrack != null) {
        _audioTrack!.enabled = false;
        _audioTrack!.stop();
        _audioTrack = null;
      }
      
      if (_localStream != null) {
        _localStream!.getTracks().forEach((track) {
          track.stop();
        });
        await _localStream!.dispose();
        _localStream = null;
      }
      
      debugPrint('[AudioService] Captura de √°udio parada com sucesso');
    } catch (e) {
      debugPrint('[AudioService] Erro ao parar captura de √°udio: $e');
    }
  }

  static MediaStreamTrack? getAudioTrack() => _audioTrack;
  static MediaStream? getMediaStream() => _localStream;
  
  /// Verifica o status atual da permiss√£o de microfone sem solicitar
  static Future<PermissionStatus> verificarStatusPermissao() async {
    try {
      final status = await Permission.microphone.status;
      debugPrint('[AudioService] üîç Status atual da permiss√£o: $status');
      return status;
    } catch (e) {
      debugPrint('[AudioService] ‚ùå Erro ao verificar status da permiss√£o: $e');
      return PermissionStatus.denied;
    }
  }
  
  /// Abre as configura√ß√µes do app para o usu√°rio conceder permiss√£o manualmente
  static Future<bool> abrirConfiguracoes() async {
    try {
      debugPrint('[AudioService] üîß Abrindo configura√ß√µes do app...');
      return await openAppSettings();
    } catch (e) {
      debugPrint('[AudioService] ‚ùå Erro ao abrir configura√ß√µes: $e');
      return false;
    }
  }
  
  /// Teste direto do WebRTC para verificar se o problema est√° na camada de permiss√£o ou no WebRTC
  static Future<bool> testarWebRTCDireto() async {
    try {
      debugPrint('[AudioService] üß™ Testando WebRTC diretamente...');
      
      final Map<String, dynamic> mediaConstraints = {
        'audio': true,
        'video': false,
      };
      
      final stream = await navigator.mediaDevices.getUserMedia(mediaConstraints);
      
      if (stream != null) {
        debugPrint('[AudioService] ‚úÖ WebRTC funcionou - stream obtido');
        await stream.dispose();
        return true;
      } else {
        debugPrint('[AudioService] ‚ùå WebRTC falhou - stream √© null');
        return false;
      }
    } catch (e, stackTrace) {
      debugPrint('[AudioService] ‚ùå Erro no teste WebRTC: $e');
      debugPrint('[AudioService] üìö Stack trace WebRTC: $stackTrace');
      return false;
    }
  }
  
  // M√©todo para mutar o √°udio
  static void muteAudio() {
    if (_audioTrack != null) {
      debugPrint('[AudioService] Mutando √°udio');
      _audioTrack!.enabled = false;
    }
  }
  
  // M√©todo para desmutar o √°udio
  static void unmuteAudio() {
    if (_audioTrack != null) {
      debugPrint('[AudioService] Desmutando √°udio');
      _audioTrack!.enabled = true;
    }
  }
  
  /// Configura o volume do √°udio remoto (resposta da IA)
  /// Nota: WebRTC n√£o suporta controle de volume direto, o volume √© controlado pelo sistema
  static void setRemoteAudioVolume(MediaStream? remoteStream, double volume) {
    if (remoteStream != null) {
      debugPrint('[AudioService] üîä Volume solicitado: ${(volume * 100).round()}%');
      debugPrint('[AudioService] ‚ö†Ô∏è WebRTC n√£o suporta controle de volume direto - use o volume do sistema');
      // O volume no WebRTC √© controlado pelo sistema operacional
      // Para iOS, o usu√°rio deve usar os bot√µes de volume f√≠sicos ou o Control Center
    }
  }
  
  /// Aumenta o volume do sistema para reprodu√ß√£o de √°udio
  static void maximizeSystemVolume() {
    try {
      debugPrint('[AudioService] üîä Configurando categoria de √°udio para reprodu√ß√£o');
      // No iOS, o volume √© controlado pelo sistema
      // A categoria de √°udio j√° √© configurada automaticamente pelo WebRTC
      
      // Tentar configurar o volume do sistema para m√°ximo
      debugPrint('[AudioService] üîä IMPORTANTE: Aumente o volume do iPhone usando os bot√µes f√≠sicos!');
      debugPrint('[AudioService] üîä Ou use o Control Center para ajustar o volume');
    } catch (e) {
      debugPrint('[AudioService] Erro ao configurar categoria de √°udio: $e');
    }
  }
  
  /// Configura as constraints de √°udio para melhor qualidade e volume
  static Map<String, dynamic> getOptimizedAudioConstraints() {
    return {
      'audio': {
        'echoCancellation': true,
        'noiseSuppression': true,
        'autoGainControl': true,
        'googEchoCancellation': true,
        'googAutoGainControl': true,
        'googNoiseSuppression': true,
        'googHighpassFilter': true,
        'googTypingNoiseDetection': true,
        'googAudioMirroring': false,
        'volume': 1.0, // M√°ximo
        'sampleRate': 48000,
        'channelCount': 1,
        // FOR√áAR USO DO ALTO-FALANTE PRINCIPAL
        'googDefaultToSpeaker': true,
        'speakerphone': true,
      },
      'video': false,
    };
  }
}
